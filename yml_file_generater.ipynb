{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#------------------------------importing library---------------------------------------\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# from bpemb import BPEmb\n",
    "import pytesseract\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "import shutil\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import xml.etree.cElementTree as ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = \"C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/0325updated.task2train(626p)/*.txt\"\n",
    "img_path = \"C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/0325updated.task2train(626p)/*.jpg\"\n",
    "tesseract_path = 'C:/python_lib/ocr/tesseract.exe'\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/python_lib/ocr/tesseract.exe'\n",
    "file_save_path='C:/Users/Sanjeev/Documents/Python Scripts/Dataset/label_data/'\n",
    "xml_file=\"C:/Users/Sanjeev/Documents/Python Scripts/NLP/TensorFlow/addons/data/X00016469612.xml\"\n",
    "img_save_path='C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/data/generated_annotation/'\n",
    "text_save_path='C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/data/generated_annotation/text_dict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path_list = glob.glob(text_path)\n",
    "img_path_list = glob.glob(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     24,
     45,
     52
    ]
   },
   "outputs": [],
   "source": [
    "def SaveData(data,path):\n",
    "    with open(path,'wb') as file:\n",
    "        pickle.dump(data,file)\n",
    "\n",
    "def LoadData(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def display_image(img):\n",
    "    res = isinstance(img, str)\n",
    "    if res:\n",
    "        print('reading image ../n' )\n",
    "        img = cv2.imread(img)  \n",
    "    if len(img.shape) > 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Image\")\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"RGB Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "def extract_bbox_info(img_path):\n",
    "    hocr_data = pytesseract.image_to_pdf_or_hocr(img_path, extension='hocr')\n",
    "    soup = BeautifulSoup(hocr_data)\n",
    "    spans = soup.find_all('span', attrs={'class':'ocrx_word'})  # getting the attributes \n",
    "    word_bbox_list =[]  \n",
    "#     bbox_width=[]\n",
    "    for span in spans:\n",
    "        bbox_str=span['title']  # geting bounding box inforamtion \n",
    "        bbox_str =bbox_str.split(';')\n",
    "        bbox =bbox_str[0].split()[1:]\n",
    "    #     x,y,w,h= *bbox\n",
    "    #     word_info_list.append([span['id'],span.string,[bbox[1].split()[-1],*bbox]])\n",
    "        word_bbox_list.append([span['id'],span.string,\n",
    "                               [int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])]\n",
    "                              ])\n",
    "#         bbox_width.append((int(bbox[2])-int(bbox[0])))\n",
    "#         word_info_list.sort(key = lambda sort_value: (sort_value[2][1],sort_value[2][0]))\n",
    "#     word_info_list.sort(key = lambda sort_value: sort_value[2][1])\n",
    "    \n",
    "    return word_bbox_list\n",
    "\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \") \n",
    "# from ElementTree_pretty import prettify\n",
    "def create_xml(bbox_list=None,path=None,img_shape=None,folder='Data'):\n",
    "    w,h,d=img_shape\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    root_c_folder = ET.SubElement(root, \"folder\").text =folder\n",
    "    root_c_filename=ET.SubElement(root, \"filename\").text =path.split('\\\\')[-1]\n",
    "    \n",
    "    root_c_path=ET.SubElement(root, \"path\").text =path\n",
    "    root_c_source=ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(root_c_source, \"database\").text = \"Unknown\"\n",
    "    \n",
    "    root_c_size=ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(root_c_size, \"width\").text = str(int(w))\n",
    "    ET.SubElement(root_c_size, \"height\").text = str(int(h))\n",
    "    ET.SubElement(root_c_size, \"depth\").text = str(int(d))\n",
    "    \n",
    "    root_c_segmented=ET.SubElement(root, \"segmented\").text=str(int(0))\n",
    "    \n",
    "    for bbox_ in bbox_list:\n",
    "        bbox =bbox_[-1]\n",
    "        root_c_object=ET.SubElement(root, \"object\")\n",
    "\n",
    "        ET.SubElement(root_c_object, \"name\").text = 'text'\n",
    "        ET.SubElement(root_c_object, \"pose\").text = 'Unspecified'\n",
    "        ET.SubElement(root_c_object, \"truncated\").text = str(int(0))\n",
    "        ET.SubElement(root_c_object, \"difficult\").text = str(int(0))\n",
    "        object_c_bndbox=ET.SubElement(root_c_object, \"bndbox\")\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[0]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[1]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[2]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[3]))\n",
    "\n",
    "    return prettify(root)\n",
    "#     tree.write(file_save_path+\"filename.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_ocr_text(img):  \n",
    "    res = isinstance(img, str)\n",
    "    if res:\n",
    "        print('reading image ../n' )\n",
    "        img = cv2.imread(img)  \n",
    "    text = pytesseract.image_to_string(img)\n",
    "#     print(text)\n",
    "    return text\n",
    "\n",
    "# read_data ()-> out data [ocr_text_list,file_name_list,word_list,dict_list,img_list,path_list]\n",
    "def read_data_xml(img_path_list, text_path_list, data_no=150):\n",
    "    word_list,dict_list,img_list,path_list,file_name_list,ocr_text_list=[],[],[],[],[],[]\n",
    "    \n",
    "    for i in range(data_no):\n",
    "        print('file : ',i, '-> remaining : ',data_no-i)\n",
    "        img_path= img_path_list[i]\n",
    "        path_list.append(img_path_list[i])\n",
    "        img_name = img_path.split(\"\\\\\")[-1]\n",
    "        img_name = img_name.split(\".jpg\")[0]\n",
    "        img_data = cv2.imread(img_path_list[i])\n",
    "        img_list.append(img_data)\n",
    "        ocr_text = get_ocr_text(img_path)\n",
    "        ocr_text_list.append(ocr_text)\n",
    "        word_list.append(extract_bbox_info(img_path_list[i]))\n",
    "        text_path = text_path_list[i]\n",
    "        text_name=text_path.split(\"\\\\\")[-1]\n",
    "        text_name = text_name.split('.txt')[0]\n",
    "        while img_name != text_name:\n",
    "            j=i \n",
    "            if img_name.split !=text_name.split(\" \")[0]:\n",
    "                break\n",
    "            else:\n",
    "\n",
    "                j +=1\n",
    "                print('fileName is not same: ',img_name, text_name)\n",
    "                text_path = text_path_list[j]\n",
    "                text_name=text_path.split(\"\\\\\")[-1]\n",
    "                text_name = text_name.split('.txt')[0]\n",
    "        with open(text_path, 'r') as file:\n",
    "            text_data =file.read()\n",
    "        dict_list.append(eval(text_data))\n",
    "        file_name_list.append(img_name)\n",
    "#         data_list.append([img_data,ocr_text,eval(text_data),img_name])    \n",
    "    return ocr_text_list,file_name_list,word_list,dict_list,img_list,path_list\n",
    "\n",
    "def read_data_yolo(img_path_list, text_path_list, data_no=150):\n",
    "    word_list,dict_list,img_list,path_list,file_name_list,ocr_text_list=[],[],[],[],[],[]\n",
    "    for i in range(data_no):\n",
    "        print('file : ',i, '-> remaining : ',data_no-i)\n",
    "        img_path= img_path_list[i]\n",
    "        path_list.append(img_path_list[i])\n",
    "        img_name = img_path.split(\"\\\\\")[-1]\n",
    "        img_name = img_name.split(\".jpg\")[0]\n",
    "        img_data = cv2.imread(img_path_list[i])\n",
    "        img_list.append(img_data)\n",
    "        ocr_text = get_ocr_text(img_path)\n",
    "        ocr_text_list.append(ocr_text)\n",
    "        word_list.append(extract_bbox_info(img_path_list[i]))\n",
    "        text_path = text_path_list[i]\n",
    "        text_name=text_path.split(\"\\\\\")[-1]\n",
    "        text_name = text_name.split('.txt')[0]\n",
    "        with open(text_path, 'r') as file:\n",
    "            text_data =file.read()\n",
    "        dict_list.append(eval(text_data))\n",
    "        file_name_list.append(img_name)\n",
    "#         data_list.append([img_data,ocr_text,eval(text_data),img_name])    \n",
    "    return ocr_text_list,file_name_list,word_list,dict_list,img_list,path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def Line_Formation(word_list):\n",
    "    word_list.sort(key =lambda sort_on_top : sort_on_top[2][1]) # sorting on top value \n",
    "    line_list =[]  \n",
    "    word_list_len = len(word_list)\n",
    "    temp=[]\n",
    "    temp.append(word_list[0])   # intializing the value with pre-assumption \n",
    "    for i in range(1,word_list_len, 1):\n",
    "        wa_top =word_list[i-1][2][1]\n",
    "        wa_bottom = word_list[i-1][2][3]\n",
    "\n",
    "        wb_top =word_list[i][2][1]\n",
    "        wb_bottom = word_list[i][2][3]\n",
    "        if wa_top <= wb_bottom and wa_bottom >= wb_top:\n",
    "            temp.append(word_list[i])\n",
    "        else:\n",
    "            temp.sort(key=lambda sort_on_left_ : sort_on_left_[2][0]) # sorting on the left value\n",
    "            line_list.append(temp)\n",
    "            temp=[]\n",
    "            temp.append(word_list[i])\n",
    "    line_list.append(temp)\n",
    "    return line_list\n",
    "\n",
    "# output-> arr_word_list, dict_list\n",
    "def create_output(word_list,dict_word,skip=None):\n",
    "    dict_list = []\n",
    "    for key,value in dict_word.items():\n",
    "        if skip==key:\n",
    "            continue\n",
    "        dict_list.append(value.split())\n",
    "\n",
    "        arr_word_list=[]\n",
    "    lines=Line_Formation(word_list)\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            arr_word_list.append(word)\n",
    "        \n",
    "    return arr_word_list, dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def get_index(text,dict_list):\n",
    "    for idx,word_list in enumerate(dict_list):\n",
    "        if text in word_list:\n",
    "            return idx\n",
    "    return -1\n",
    "\n",
    "def get_bbox_list(arr_word_list,dict_list):\n",
    "    bbox_list,idx =[],0\n",
    "    while idx < len(arr_word_list):\n",
    "        text= arr_word_list[idx][1]\n",
    "        value_idx = get_index(text,dict_list)\n",
    "        if value_idx ==-1:\n",
    "            idx +=1\n",
    "            continue\n",
    "#         print('value_id : ',value_idx,'idx ', idx, 'text = ', text)\n",
    "#         print(text,\"--->\", dict_list[value_idx])\n",
    "        if text in dict_list[value_idx]:     #case when 1st word matches\n",
    "            l=dict_list[value_idx].index(text) # if index is not zero\n",
    "#             print('-------> index check (',text,'): ', l )\n",
    "            j=0\n",
    "            if l != 0:\n",
    "#                 print('case when l not eaual to zero vlaue l ', l)\n",
    "                j=l\n",
    "                while l > 0:\n",
    "#                     print('appending word: ',arr_word_list[idx-l])\n",
    "                    bbox_list.append(arr_word_list[idx-l])\n",
    "                    l=l-1\n",
    "            while j < len(dict_list[value_idx]) and arr_word_list[idx][1] != dict_list[value_idx][-1]:  \n",
    "                bbox_list.append(arr_word_list[idx])  # todo what should be the output data actural data or extracted one (now). \n",
    "                idx +=1\n",
    "                j +=1\n",
    "            bbox_list.append(arr_word_list[idx])\n",
    "            del dict_list[value_idx]\n",
    "            value_idx +=1\n",
    "        idx +=1\n",
    "    return bbox_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image ../n\n",
      "reading image ../n\n",
      "fileName is not same:  X00016469619 X00016469612\n"
     ]
    }
   ],
   "source": [
    "_,_,word_list,dict_list,img_list,path_list = read_data_xml(img_path_list, text_path_list, data_no=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_annotation(word_list, dict_list, img_list, path_list, file_save_path=''):\n",
    "    \n",
    "    file_len =len(word_list)\n",
    "    \n",
    "    for idx in range(file_len):\n",
    "        \n",
    "        arr_word_list, dict_text_list = create_output(word_list[idx],dict_list[idx])\n",
    "        bbox_list = get_bbox_list(arr_word_list,dict_text_list)\n",
    "\n",
    "        xml_text=create_xml(bbox_list,path_list[idx],img_list[idx].shape,folder='Data')\n",
    "        file_name = path_list[idx].split('\\\\')[-1]\n",
    "        file_name=file_name.split('.')[0]+'.xml'\n",
    "        with open(file_save_path+file_name, \"w\") as file:\n",
    "            file.write(xml_text)\n",
    "        print(xml_text,'\\n\\n---------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-247a7a1963f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_xml_annotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_save_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_list' is not defined"
     ]
    }
   ],
   "source": [
    "create_xml_annotation(word_list, dict_list, img_list, path_list,file_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_save_path =img_save_path+'temp/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy_data ()-> out data [image_list,ocr_text,out_text,file_name]\n",
    "def copy_data(img_path_list, text_path_list,img_save_path, data_no=150):\n",
    "    img_list,ocr_text_list,text_list,file_name_list=[],[],[],[]\n",
    "    \n",
    "    for i in range(data_no):\n",
    "        img_path= img_path_list[i]\n",
    "        img_name = img_path.split(\"\\\\\")[-1]\n",
    "        shutil.copyfile(img_path, img_save_path+img_path.split(\"\\\\\")[-1])\n",
    "#         img_name=img_name.split('.')[0]\n",
    "#         text_path = text_path_list[i]\n",
    "#         text_name=text_path.split(\"\\\\\")[-1]\n",
    "#         text_name = text_name.split('.txt')[0]\n",
    "#         while img_name != text_name:\n",
    "#             j=i\n",
    "#             if img_name.split !=text_name.split(\" \")[0]:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 j +=1\n",
    "#                 print('fileName is not same: ',img_name, text_name)\n",
    "#                 text_path = text_path_list[j]\n",
    "#                 text_name=text_path.split(\"\\\\\")[-1]\n",
    "#                 text_name = text_name.split('.txt')[0]\n",
    "#         print(i,img_name,text_name) \n",
    "#         shutil.copyfile(text_path, text_save_path+text_path.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_data(img_path_list,text_path_list,img_save_path,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "text_path_list = glob.glob(text_save_path + '*.txt')\n",
    "img_path_list = glob.glob(img_save_path+'*.jpg')\n",
    "print(len(text_path_list),len(text_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n",
      "reading image ../n\n"
     ]
    }
   ],
   "source": [
    "_,_,word_list,dict_list,img_list,path_list = read_data_yolo(img_path_list, text_path_list, data_no=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_annotation(word_list, dict_list, img_list, path_list, file_save_path=''):\n",
    "    \n",
    "    file_len =len(word_list)\n",
    "    class_id =0\n",
    "    \n",
    "    for idx in range(file_len):\n",
    "        print('file : ',idx, '-> remaining : ',200-idx)\n",
    "        arr_word_list, dict_text_list = create_output(word_list[idx],dict_list[idx],skip='total')\n",
    "        bbox_list = get_bbox_list(arr_word_list,dict_text_list)\n",
    "        X,Y,_ =img_list[idx].shape\n",
    "        file_name = path_list[idx].split(\"\\\\\")[-1]\n",
    "        file_name=file_name.split('.')[0]\n",
    "#         print(file_save_path +file_name+'.txt')\n",
    "        with open(file_save_path +file_name+'.txt', 'w') as file:\n",
    "            \n",
    "            for bbox in bbox_list:\n",
    "                x,y,w,h=bbox[-1]\n",
    "                x0=round((x+(w-x)/2)/Y, 6)\n",
    "                y0=round((y+(h-y)/2)/X, 6)\n",
    "                W=round((w-x)/Y, 6)\n",
    "                H=round((h-y)/X, 6)\n",
    "                file.writelines(str(class_id)+' '+str(x0)+' '+str(y0)+' '+str(W)+' '+str(H)+'\\n')\n",
    "            #             print('x={},y={},W={},h={}'.format(bbox[-1][0],bbox[-1][1],bbox[-1][2],bbox[-1][3]))\n",
    "#             print('w-x(x2)={},h-y(y2)={}'.format(bbox[-1][2] - bbox[-1][0], bbox[-1][3]- bbox[-1][1]))\n",
    "#             print('u-> w-x(x2)={},h-y(y2)={}'.format(bbox[-1][0] - bbox[-1][2], bbox[-1][1]- bbox[-1][3]))\n",
    "# #             print('w-x(W)={},h-y(H)={}'.format((bbox[-1][2] - bbox[-1][0])/X, (bbox[-1][3]- bbox[-1][1]))/Y)\n",
    "#             print('{} {} {} {} {}'.format(class_id,x0,y0,W,H)) \n",
    "#             break\n",
    "#         print('\\n-------------next\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file :  0 -> remaining :  200\n",
      "file :  1 -> remaining :  199\n",
      "file :  2 -> remaining :  198\n",
      "file :  3 -> remaining :  197\n",
      "file :  4 -> remaining :  196\n",
      "file :  5 -> remaining :  195\n",
      "file :  6 -> remaining :  194\n",
      "file :  7 -> remaining :  193\n",
      "file :  8 -> remaining :  192\n",
      "file :  9 -> remaining :  191\n",
      "file :  10 -> remaining :  190\n",
      "file :  11 -> remaining :  189\n",
      "file :  12 -> remaining :  188\n",
      "file :  13 -> remaining :  187\n",
      "file :  14 -> remaining :  186\n",
      "file :  15 -> remaining :  185\n",
      "file :  16 -> remaining :  184\n",
      "file :  17 -> remaining :  183\n",
      "file :  18 -> remaining :  182\n",
      "file :  19 -> remaining :  181\n",
      "file :  20 -> remaining :  180\n",
      "file :  21 -> remaining :  179\n",
      "file :  22 -> remaining :  178\n",
      "file :  23 -> remaining :  177\n",
      "file :  24 -> remaining :  176\n",
      "file :  25 -> remaining :  175\n",
      "file :  26 -> remaining :  174\n",
      "file :  27 -> remaining :  173\n",
      "file :  28 -> remaining :  172\n",
      "file :  29 -> remaining :  171\n",
      "file :  30 -> remaining :  170\n",
      "file :  31 -> remaining :  169\n",
      "file :  32 -> remaining :  168\n",
      "file :  33 -> remaining :  167\n",
      "file :  34 -> remaining :  166\n",
      "file :  35 -> remaining :  165\n",
      "file :  36 -> remaining :  164\n",
      "file :  37 -> remaining :  163\n",
      "file :  38 -> remaining :  162\n",
      "file :  39 -> remaining :  161\n",
      "file :  40 -> remaining :  160\n",
      "file :  41 -> remaining :  159\n",
      "file :  42 -> remaining :  158\n",
      "file :  43 -> remaining :  157\n",
      "file :  44 -> remaining :  156\n",
      "file :  45 -> remaining :  155\n",
      "file :  46 -> remaining :  154\n",
      "file :  47 -> remaining :  153\n",
      "file :  48 -> remaining :  152\n",
      "file :  49 -> remaining :  151\n",
      "file :  50 -> remaining :  150\n",
      "file :  51 -> remaining :  149\n",
      "file :  52 -> remaining :  148\n",
      "file :  53 -> remaining :  147\n",
      "file :  54 -> remaining :  146\n",
      "file :  55 -> remaining :  145\n",
      "file :  56 -> remaining :  144\n",
      "file :  57 -> remaining :  143\n",
      "file :  58 -> remaining :  142\n",
      "file :  59 -> remaining :  141\n",
      "file :  60 -> remaining :  140\n",
      "file :  61 -> remaining :  139\n",
      "file :  62 -> remaining :  138\n",
      "file :  63 -> remaining :  137\n",
      "file :  64 -> remaining :  136\n",
      "file :  65 -> remaining :  135\n",
      "file :  66 -> remaining :  134\n",
      "file :  67 -> remaining :  133\n",
      "file :  68 -> remaining :  132\n",
      "file :  69 -> remaining :  131\n",
      "file :  70 -> remaining :  130\n",
      "file :  71 -> remaining :  129\n",
      "file :  72 -> remaining :  128\n",
      "file :  73 -> remaining :  127\n",
      "file :  74 -> remaining :  126\n",
      "file :  75 -> remaining :  125\n",
      "file :  76 -> remaining :  124\n",
      "file :  77 -> remaining :  123\n",
      "file :  78 -> remaining :  122\n",
      "file :  79 -> remaining :  121\n",
      "file :  80 -> remaining :  120\n",
      "file :  81 -> remaining :  119\n",
      "file :  82 -> remaining :  118\n",
      "file :  83 -> remaining :  117\n",
      "file :  84 -> remaining :  116\n",
      "file :  85 -> remaining :  115\n",
      "file :  86 -> remaining :  114\n",
      "file :  87 -> remaining :  113\n",
      "file :  88 -> remaining :  112\n",
      "file :  89 -> remaining :  111\n",
      "file :  90 -> remaining :  110\n",
      "file :  91 -> remaining :  109\n",
      "file :  92 -> remaining :  108\n",
      "file :  93 -> remaining :  107\n",
      "file :  94 -> remaining :  106\n",
      "file :  95 -> remaining :  105\n",
      "file :  96 -> remaining :  104\n",
      "file :  97 -> remaining :  103\n",
      "file :  98 -> remaining :  102\n",
      "file :  99 -> remaining :  101\n",
      "file :  100 -> remaining :  100\n",
      "file :  101 -> remaining :  99\n",
      "file :  102 -> remaining :  98\n",
      "file :  103 -> remaining :  97\n",
      "file :  104 -> remaining :  96\n",
      "file :  105 -> remaining :  95\n",
      "file :  106 -> remaining :  94\n",
      "file :  107 -> remaining :  93\n",
      "file :  108 -> remaining :  92\n",
      "file :  109 -> remaining :  91\n",
      "file :  110 -> remaining :  90\n",
      "file :  111 -> remaining :  89\n",
      "file :  112 -> remaining :  88\n",
      "file :  113 -> remaining :  87\n",
      "file :  114 -> remaining :  86\n",
      "file :  115 -> remaining :  85\n",
      "file :  116 -> remaining :  84\n",
      "file :  117 -> remaining :  83\n",
      "file :  118 -> remaining :  82\n",
      "file :  119 -> remaining :  81\n",
      "file :  120 -> remaining :  80\n",
      "file :  121 -> remaining :  79\n",
      "file :  122 -> remaining :  78\n",
      "file :  123 -> remaining :  77\n",
      "file :  124 -> remaining :  76\n",
      "file :  125 -> remaining :  75\n",
      "file :  126 -> remaining :  74\n",
      "file :  127 -> remaining :  73\n",
      "file :  128 -> remaining :  72\n",
      "file :  129 -> remaining :  71\n",
      "file :  130 -> remaining :  70\n",
      "file :  131 -> remaining :  69\n",
      "file :  132 -> remaining :  68\n",
      "file :  133 -> remaining :  67\n",
      "file :  134 -> remaining :  66\n",
      "file :  135 -> remaining :  65\n",
      "file :  136 -> remaining :  64\n",
      "file :  137 -> remaining :  63\n",
      "file :  138 -> remaining :  62\n",
      "file :  139 -> remaining :  61\n",
      "file :  140 -> remaining :  60\n",
      "file :  141 -> remaining :  59\n",
      "file :  142 -> remaining :  58\n",
      "file :  143 -> remaining :  57\n",
      "file :  144 -> remaining :  56\n",
      "file :  145 -> remaining :  55\n",
      "file :  146 -> remaining :  54\n",
      "file :  147 -> remaining :  53\n",
      "file :  148 -> remaining :  52\n",
      "file :  149 -> remaining :  51\n",
      "file :  150 -> remaining :  50\n",
      "file :  151 -> remaining :  49\n",
      "file :  152 -> remaining :  48\n",
      "file :  153 -> remaining :  47\n",
      "file :  154 -> remaining :  46\n",
      "file :  155 -> remaining :  45\n",
      "file :  156 -> remaining :  44\n",
      "file :  157 -> remaining :  43\n",
      "file :  158 -> remaining :  42\n",
      "file :  159 -> remaining :  41\n",
      "file :  160 -> remaining :  40\n",
      "file :  161 -> remaining :  39\n",
      "file :  162 -> remaining :  38\n",
      "file :  163 -> remaining :  37\n",
      "file :  164 -> remaining :  36\n",
      "file :  165 -> remaining :  35\n",
      "file :  166 -> remaining :  34\n",
      "file :  167 -> remaining :  33\n",
      "file :  168 -> remaining :  32\n",
      "file :  169 -> remaining :  31\n",
      "file :  170 -> remaining :  30\n",
      "file :  171 -> remaining :  29\n",
      "file :  172 -> remaining :  28\n",
      "file :  173 -> remaining :  27\n",
      "file :  174 -> remaining :  26\n",
      "file :  175 -> remaining :  25\n",
      "file :  176 -> remaining :  24\n",
      "file :  177 -> remaining :  23\n",
      "file :  178 -> remaining :  22\n",
      "file :  179 -> remaining :  21\n",
      "file :  180 -> remaining :  20\n",
      "file :  181 -> remaining :  19\n",
      "file :  182 -> remaining :  18\n",
      "file :  183 -> remaining :  17\n",
      "file :  184 -> remaining :  16\n",
      "file :  185 -> remaining :  15\n",
      "file :  186 -> remaining :  14\n",
      "file :  187 -> remaining :  13\n",
      "file :  188 -> remaining :  12\n",
      "file :  189 -> remaining :  11\n",
      "file :  190 -> remaining :  10\n",
      "file :  191 -> remaining :  9\n",
      "file :  192 -> remaining :  8\n",
      "file :  193 -> remaining :  7\n",
      "file :  194 -> remaining :  6\n",
      "file :  195 -> remaining :  5\n",
      "file :  196 -> remaining :  4\n",
      "file :  197 -> remaining :  3\n",
      "file :  198 -> remaining :  2\n",
      "file :  199 -> remaining :  1\n"
     ]
    }
   ],
   "source": [
    "create_yolo_annotation(word_list, dict_list, img_list, path_list,img_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(52/463)\n",
    "print((109-97)/1013)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "xml_f=\"C:/Users/Sanjeev/Documents/Python Scripts/Dataset/label_data/X00016469612.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "# parse an xml file by name\n",
    "mydoc = minidom.parse(xml_f)\n",
    "\n",
    "items = mydoc.getElementsByTagName('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xml_f)\n",
    "root = tree.getroot()\n",
    "print('\\nAll item data:')\n",
    "for elem in root:\n",
    "    for subelem in elem:\n",
    "        print(subelem.text)\n",
    "        for bbox in subelem:\n",
    "            print('bbox :-> ',bbox.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path_list = glob.glob(text_path)\n",
    "img_path_list = glob.glob(img_path)\n",
    "print(len(text_path_list) , len(img_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(img_path_list)):\n",
    "    if img_path_list[i].split(\"\\\\\")[0] == text_path_list[i].split(\"\\\\\")[0]:\n",
    "        continue\n",
    "    else:\n",
    "        print('data is not same for : ',i ,\" \\n\",img_path_list[i].split(\"\\\\\")[0],\" \\n\",text_path_list[i].split(\"\\\\\")[0])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trevaller_policy",
   "language": "python",
   "name": "trevaller_policy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
