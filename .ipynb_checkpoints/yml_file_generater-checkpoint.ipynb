{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#------------------------------importing library---------------------------------------\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# from bpemb import BPEmb\n",
    "import pytesseract\n",
    "import cv2\n",
    "import glob\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import xml.etree.cElementTree as ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = \"C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/0325updated.task2train(626p)/*.txt\"\n",
    "img_path = \"C:/Users/Sanjeev/Downloads/software/0325updated.task2train(626p)-20200414T125907Z-001/0325updated.task2train(626p)/*.jpg\"\n",
    "tesseract_path = 'C:/python_lib/ocr/tesseract.exe'\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/python_lib/ocr/tesseract.exe'\n",
    "file_save_path='C:/Users/Sanjeev/Documents/Python Scripts/Dataset/label_data/'\n",
    "xml_file=\"C:/Users/Sanjeev/Documents/Python Scripts/NLP/TensorFlow/addons/data/X00016469612.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path_list = glob.glob(text_path)\n",
    "img_path_list = glob.glob(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     24,
     45
    ]
   },
   "outputs": [],
   "source": [
    "def SaveData(data,path):\n",
    "    with open(path,'wb') as file:\n",
    "        pickle.dump(data,file)\n",
    "\n",
    "def LoadData(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def display_image(img):\n",
    "    res = isinstance(img, str)\n",
    "    if res:\n",
    "        print('reading image ../n' )\n",
    "        img = cv2.imread(img)  \n",
    "    if len(img.shape) > 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(\"Image\")\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"RGB Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "def extract_bbox_info(img_path):\n",
    "    hocr_data = pytesseract.image_to_pdf_or_hocr(img_path, extension='hocr')\n",
    "    soup = BeautifulSoup(hocr_data)\n",
    "    spans = soup.find_all('span', attrs={'class':'ocrx_word'})  # getting the attributes \n",
    "    word_bbox_list =[]  \n",
    "#     bbox_width=[]\n",
    "    for span in spans:\n",
    "        bbox_str=span['title']  # geting bounding box inforamtion \n",
    "        bbox_str =bbox_str.split(';')\n",
    "        bbox =bbox_str[0].split()[1:]\n",
    "    #     x,y,w,h= *bbox\n",
    "    #     word_info_list.append([span['id'],span.string,[bbox[1].split()[-1],*bbox]])\n",
    "        word_bbox_list.append([span['id'],span.string,\n",
    "                               [int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])]\n",
    "                              ])\n",
    "#         bbox_width.append((int(bbox[2])-int(bbox[0])))\n",
    "#         word_info_list.sort(key = lambda sort_value: (sort_value[2][1],sort_value[2][0]))\n",
    "#     word_info_list.sort(key = lambda sort_value: sort_value[2][1])\n",
    "    \n",
    "    return word_bbox_list\n",
    "\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \") \n",
    "# from ElementTree_pretty import prettify\n",
    "def create_xml(bbox_list=None,path=None,img_shape=None,folder='Data'):\n",
    "    w,h,d=img_shape\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    root_c_folder = ET.SubElement(root, \"folder\").text =folder\n",
    "    root_c_filename=ET.SubElement(root, \"filename\").text =path.split('\\\\')[-1]\n",
    "    \n",
    "    root_c_path=ET.SubElement(root, \"path\").text =path\n",
    "    root_c_source=ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(root_c_source, \"database\").text = \"Unknown\"\n",
    "    \n",
    "    root_c_size=ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(root_c_size, \"width\").text = str(int(w))\n",
    "    ET.SubElement(root_c_size, \"height\").text = str(int(h))\n",
    "    ET.SubElement(root_c_size, \"depth\").text = str(int(d))\n",
    "    \n",
    "    root_c_segmented=ET.SubElement(root, \"segmented\").text=str(int(0))\n",
    "    \n",
    "    for bbox_ in bbox_list:\n",
    "        bbox =bbox_[-1]\n",
    "        root_c_object=ET.SubElement(root, \"object\")\n",
    "\n",
    "        ET.SubElement(root_c_object, \"name\").text = 'text'\n",
    "        ET.SubElement(root_c_object, \"pose\").text = 'Unspecified'\n",
    "        ET.SubElement(root_c_object, \"truncated\").text = str(int(0))\n",
    "        ET.SubElement(root_c_object, \"difficult\").text = str(int(0))\n",
    "        object_c_bndbox=ET.SubElement(root_c_object, \"bndbox\")\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[0]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[1]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[2]))\n",
    "        ET.SubElement(object_c_bndbox, \"xmin\").text = str(int(bbox[3]))\n",
    "\n",
    "    return prettify(root)\n",
    "#     tree.write(file_save_path+\"filename.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def get_ocr_text(img):  \n",
    "    res = isinstance(img, str)\n",
    "    if res:\n",
    "        print('reading image ../n' )\n",
    "        img = cv2.imread(img)  \n",
    "    text = pytesseract.image_to_string(img)\n",
    "#     print(text)\n",
    "    return text\n",
    "\n",
    "# read_data ()-> out data [ocr_text_list,file_name_list,word_list,dict_list,img_list,path_list]\n",
    "def read_data(img_path_list, text_path_list, data_no=150):\n",
    "    word_list,dict_list,img_list,path_list,file_name_list,ocr_text_list=[],[],[],[],[],[]\n",
    "    j=0\n",
    "    for i in range(data_no):\n",
    "        img_path= img_path_list[i]\n",
    "        path_list.append(img_path_list[i])\n",
    "        img_name = img_path.split(\"\\\\\")[-1]\n",
    "        img_name = img_name.split(\".jpg\")[0]\n",
    "        img_data = cv2.imread(img_path_list[i])\n",
    "        img_list.append(img_data)\n",
    "        ocr_text = get_ocr_text(img_path)\n",
    "        ocr_text_list.append(ocr_text)\n",
    "        word_list.append(extract_bbox_info(img_path_list[i]))\n",
    "        text_path = text_path_list[j]\n",
    "        text_name=text_path.split(\"\\\\\")[-1]\n",
    "        text_name = text_name.split('.txt')[0]\n",
    "        while img_name != text_name:\n",
    "            j +=1\n",
    "            print('fileName is not same: ',img_name, text_name)\n",
    "            text_path = text_path_list[j]\n",
    "            text_name=text_path.split(\"\\\\\")[-1]\n",
    "            text_name = text_name.split('.txt')[0]\n",
    "        with open(text_path, 'r') as file:\n",
    "            text_data =file.read()\n",
    "        dict_list.append(eval(text_data))\n",
    "        file_name_list.append(img_name)\n",
    "#         data_list.append([img_data,ocr_text,eval(text_data),img_name])    \n",
    "    return ocr_text_list,file_name_list,word_list,dict_list,img_list,path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "code_folding": [
     0,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def Line_Formation(word_list):\n",
    "    word_list.sort(key =lambda sort_on_top : sort_on_top[2][1]) # sorting on top value \n",
    "    line_list =[]  \n",
    "    word_list_len = len(word_list)\n",
    "    temp=[]\n",
    "    temp.append(word_list[0])   # intializing the value with pre-assumption \n",
    "    for i in range(1,word_list_len, 1):\n",
    "        wa_top =word_list[i-1][2][1]\n",
    "        wa_bottom = word_list[i-1][2][3]\n",
    "\n",
    "        wb_top =word_list[i][2][1]\n",
    "        wb_bottom = word_list[i][2][3]\n",
    "        if wa_top <= wb_bottom and wa_bottom >= wb_top:\n",
    "            temp.append(word_list[i])\n",
    "        else:\n",
    "            temp.sort(key=lambda sort_on_left_ : sort_on_left_[2][0]) # sorting on the left value\n",
    "            line_list.append(temp)\n",
    "            temp=[]\n",
    "            temp.append(word_list[i])\n",
    "    line_list.append(temp)\n",
    "    return line_list\n",
    "\n",
    "# output-> arr_word_list, dict_list\n",
    "def create_output(word_list,dict_word):\n",
    "    dict_list = []\n",
    "    for value in dict_word.values():\n",
    "        dict_list.append(value.split())\n",
    "\n",
    "        arr_word_list=[]\n",
    "    lines=Line_Formation(word_list)\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            arr_word_list.append(word)\n",
    "        \n",
    "    return arr_word_list, dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def get_index(text,dict_list):\n",
    "    for idx,word_list in enumerate(dict_list):\n",
    "        if text in word_list:\n",
    "            return idx\n",
    "    return -1\n",
    "\n",
    "def get_bbox_list(arr_word_list,dict_list):\n",
    "    bbox_list,idx =[],0\n",
    "    while idx < len(arr_word_list):\n",
    "        text= arr_word_list[idx][1]\n",
    "        value_idx = get_index(text,dict_list)\n",
    "        if value_idx ==-1:\n",
    "            idx +=1\n",
    "            continue\n",
    "#         print('value_id : ',value_idx,'idx ', idx, 'text = ', text)\n",
    "#         print(text,\"--->\", dict_list[value_idx])\n",
    "        if text in dict_list[value_idx]:     #case when 1st word matches\n",
    "            l=dict_list[value_idx].index(text) # if index is not zero\n",
    "#             print('-------> index check (',text,'): ', l )\n",
    "            j=0\n",
    "            if l != 0:\n",
    "#                 print('case when l not eaual to zero vlaue l ', l)\n",
    "                j=l\n",
    "                while l > 0:\n",
    "#                     print('appending word: ',arr_word_list[idx-l])\n",
    "                    bbox_list.append(arr_word_list[idx-l])\n",
    "                    l=l-1\n",
    "            while j < len(dict_list[value_idx]) and arr_word_list[idx][1] != dict_list[value_idx][-1]:  \n",
    "                bbox_list.append(arr_word_list[idx])  # todo what should be the output data actural data or extracted one (now). \n",
    "                idx +=1\n",
    "                j +=1\n",
    "            bbox_list.append(arr_word_list[idx])\n",
    "            del dict_list[value_idx]\n",
    "            value_idx +=1\n",
    "        idx +=1\n",
    "    return bbox_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image ../n\n",
      "reading image ../n\n",
      "fileName is not same:  X00016469619 X00016469612\n"
     ]
    }
   ],
   "source": [
    "_,_,word_list,dict_list,img_list,path_list = read_data(img_path_list, text_path_list, data_no=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_annotation(word_list, dict_list, img_list, path_list, file_save_path=''):\n",
    "    \n",
    "    file_len =len(word_list)\n",
    "    \n",
    "    for idx in range(file_len):\n",
    "        \n",
    "        arr_word_list, dict_text_list = create_output(word_list[idx],dict_list[idx])\n",
    "        bbox_list = get_bbox_list(arr_word_list,dict_text_list)\n",
    "\n",
    "        xml_text=create_xml(bbox_list,path_list[idx],img_list[idx].shape,folder='Data')\n",
    "        file_name = path_list[idx].split('\\\\')[-1]\n",
    "        file_name=file_name.split('.')[0]+'.xml'\n",
    "        with open(file_save_path+file_name, \"w\") as file:\n",
    "            file.write(xml_text)\n",
    "#         print(xml_text,'\\n\\n---------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_xml_annotation(word_list, dict_list, img_list, path_list,file_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['BOOK', 'TA', '.K', '(TAMAN', 'DAYA)', 'SDN', 'BHD'], ['25/12/2018'], ['NO.53', '55,57', '&', '59,', 'JALAN', 'SAGU', '18,', 'TAMAN', 'DAYA,', '81100', 'JOHOR', 'BAHRU,', 'JOHOR.'], ['9.00']]\n",
      "['tan', 'woon', 'yann', 'BOOK', 'TA-K', '(TAMAN', 'DAYA)', 'SDN', 'BHD', 'B94', '7-W', 'NO.5?', '55,57', '&', '59,', 'JALAN', 'SAGU', '18,', 'TAMAN', 'DAYA', '81100', 'JOHOR', 'BAHRU,', 'JOHOR.', 'LAM', 'MCU', 'Document', 'Ho', ':', 'TDO1167104', 'Date', '25/12/2018', '8:13:39', 'PM', 'Cashier', 'MANIS', 'Member', 'CASH', 'BILL', 'CODE/DESC', 'PRICE', '—', 'Disc', 'AMOUIT', 'Quy', 'RM', 'RM', '9556939040118', 'KF', 'MODELLING', 'CLAY', 'KIDDY', ' ', 'FISH', '1PC', '*', '9.00)', '6,00', '9.00', 'Total', ':', '9.00', 'Rour', 'ding', 'Adjustment', '0.00', 'Round:', ':d', 'Total', '(RM):', '9.60', 'Cash', ' ', 'CHANGE', 'GOODS', 'SOLD', 'ARE', 'NOT', 'RETURNAR', 'EXCHANGEABLE', ' ', 'THANK', 'YOU.', 'PLEASE', 'COME', 'AGATY', 't']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr_word_list,dict_list = create_out(d[2][0],d[3][0])\n",
    "print(dict_list)\n",
    "print([word[1] for word in arr_word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_id :  0 idx  3 text =  BOOK\n",
      "BOOK ---> ['BOOK', 'TA', '.K', '(TAMAN', 'DAYA)', 'SDN', 'BHD']\n",
      "-------> index check ( BOOK ):  0\n",
      "value_id :  1 idx  12 text =  55,57\n",
      "55,57 ---> ['NO.53', '55,57', '&', '59,', 'JALAN', 'SAGU', '18,', 'TAMAN', 'DAYA,', '81100', 'JOHOR', 'BAHRU,', 'JOHOR.']\n",
      "-------> index check ( 55,57 ):  1\n",
      "case when l not eaual to zero vlaue l  1\n",
      "appending word:  ['word_1_12', 'NO.5?', [112, 147, 155, 161]]\n",
      "value_id :  0 idx  31 text =  25/12/2018\n",
      "25/12/2018 ---> ['25/12/2018']\n",
      "-------> index check ( 25/12/2018 ):  0\n",
      "value_id :  0 idx  58 text =  9.00\n",
      "9.00 ---> ['9.00']\n",
      "-------> index check ( 9.00 ):  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['word_1_4', 'BOOK', [73, 97, 125, 110]],\n",
       " ['word_1_5', 'TA-K', [132, 97, 178, 110]],\n",
       " ['word_1_6', '(TAMAN', [186, 95, 261, 112]],\n",
       " ['word_1_7', 'DAYA)', [269, 95, 327, 112]],\n",
       " ['word_1_8', 'SDN', [335, 96, 370, 109]],\n",
       " ['word_1_9', 'BHD', [380, 96, 419, 109]],\n",
       " ['word_1_12', 'NO.5?', [112, 147, 155, 161]],\n",
       " ['word_1_13', '55,57', [165, 147, 204, 163]],\n",
       " ['word_1_14', '&', [211, 147, 221, 159]],\n",
       " ['word_1_15', '59,', [229, 147, 248, 162]],\n",
       " ['word_1_16', 'JALAN', [260, 147, 303, 160]],\n",
       " ['word_1_17', 'SAGU', [311, 146, 353, 159]],\n",
       " ['word_1_18', '18,', [364, 146, 381, 162]],\n",
       " ['word_1_19', 'TAMAN', [196, 170, 247, 184]],\n",
       " ['word_1_20', 'DAYA', [255, 170, 295, 184]],\n",
       " ['word_1_21', '81100', [164, 195, 209, 208]],\n",
       " ['word_1_22', 'JOHOR', [215, 194, 268, 207]],\n",
       " ['word_1_23', 'BAHRU,', [276, 194, 329, 208]],\n",
       " ['word_1_24', 'JOHOR.', [219, 217, 271, 231]],\n",
       " ['word_1_33', '25/12/2018', [165, 373, 250, 389]],\n",
       " ['word_1_59', '9.00', [412, 599, 443, 610]]]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bbox_list(arr_word_list,dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading image ../n\n"
     ]
    }
   ],
   "source": [
    "d=read_data(img_file,text_file,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tan', 'woon', 'yann', 'BOOK', 'TAK', '(TAMAN', 'DAYA)', 'SDN', 'BHD', 'B97', 'NO.5?', '55,57', '&', '59,', 'JALAN', 'SAGU', '18,', 'TAMAN', 'DAYA', '81100', 'JOHOR', 'BAHRU,', 'JOHOR.', 'WAM', 'MICA', 'A', 'Document', 'Ho', ':', 'TDO1167104', 'Date', '25/12/2018', '8:13:39', 'PM', 'Cashier', 'MANIS', 'Member', 'CASH', 'BILL', 'CODE/DESC', 'PRICE', 'Disc', 'AMOUITT', 'Quy', 'RM', 'RM', '9556939040118', 'KF', 'MODELLING', 'CLAY', 'KIDDY', 'FISH', '1PC', '*', '9.00)', '6,00', '9.00', 'Total', ':', '9,00', 'Rour', 'ding', 'Adjustment', '0.00', 'Round::d', 'Total', '(RM):', '9.60', 'Cash', 'CHANGE', 'GOODS', 'SOLD', 'ARE', 'NOT', 'RETURNAR', 'EXCHANGEABLE', 'THANK', 'YOU.', 'PLEASE', 'COME', 'AGA', 't']\n",
      "['tan', 'woon', 'yann', 'BOOK', 'TA-K', '(TAMAN', 'DAYA)', 'SDN', 'BHD', 'B94', '7-W', 'NO.5?', '55,57', '&', '59,', 'JALAN', 'SAGU', '18,', 'TAMAN', 'DAYA', '81100', 'JOHOR', 'BAHRU,', 'JOHOR.', 'LAM', 'MCU', 'Document', 'Ho', ':', 'TDO1167104', ' ', 'Date', '25/12/2018', '8:13:39', 'PM', 'Cashier', 'MANIS', 'Member', 'CASH', 'BILL', 'CODE/DESC', 'PRICE', '—', 'Disc', 'AMOUIT', 'Quy', 'RM', 'RM', '9556939040118', 'KF', 'MODELLING', 'CLAY', 'KIDDY', 'FISH', '1PC', '*', '9.00)', '6,00', '9.00', 'Total', ':', '9.00', 'Rour', 'ding', 'Adjustment', '0.00', 'Round:', ':d', 'Total', '(RM):', '9.60', 'Cash', 'CHANGE', ' ', 'GOODS', 'SOLD', 'ARE', 'NOT', 'RETURNAR', 'EXCHANGEABLE', ' ', 'THANK', 'YOU.', 'PLEASE', 'COME', 'AGATY', 't']\n"
     ]
    }
   ],
   "source": [
    "print(d[1][0].split())\n",
    "\n",
    "print([text[1] for text in d[2][0]])\n",
    "\n",
    "# display_image(d[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "xml_f=\"C:/Users/Sanjeev/Documents/Python Scripts/Dataset/label_data/X00016469612.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "# parse an xml file by name\n",
    "mydoc = minidom.parse(xml_f)\n",
    "\n",
    "items = mydoc.getElementsByTagName('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DOM Element: object at 0x163b766acc8>,\n",
       " <DOM Element: object at 0x163b7672368>,\n",
       " <DOM Element: object at 0x163b76729a8>,\n",
       " <DOM Element: object at 0x163b767a048>,\n",
       " <DOM Element: object at 0x163b767a688>,\n",
       " <DOM Element: object at 0x163b767acc8>,\n",
       " <DOM Element: object at 0x163b767b368>,\n",
       " <DOM Element: object at 0x163b767b9a8>,\n",
       " <DOM Element: object at 0x163b767f048>,\n",
       " <DOM Element: object at 0x163b767f688>,\n",
       " <DOM Element: object at 0x163b767fcc8>,\n",
       " <DOM Element: object at 0x163b7683368>,\n",
       " <DOM Element: object at 0x163b76839a8>,\n",
       " <DOM Element: object at 0x163b7676048>,\n",
       " <DOM Element: object at 0x163b7676688>,\n",
       " <DOM Element: object at 0x163b7676cc8>,\n",
       " <DOM Element: object at 0x163b7688368>,\n",
       " <DOM Element: object at 0x163b76889a8>,\n",
       " <DOM Element: object at 0x163b768b048>,\n",
       " <DOM Element: object at 0x163b768b688>,\n",
       " <DOM Element: object at 0x163b768bcc8>]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All item data:\n",
      "Unknown\n",
      "1013\n",
      "463\n",
      "3\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  73\n",
      "bbox :->  97\n",
      "bbox :->  125\n",
      "bbox :->  110\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  132\n",
      "bbox :->  97\n",
      "bbox :->  178\n",
      "bbox :->  110\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  186\n",
      "bbox :->  95\n",
      "bbox :->  261\n",
      "bbox :->  112\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  269\n",
      "bbox :->  95\n",
      "bbox :->  327\n",
      "bbox :->  112\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  335\n",
      "bbox :->  96\n",
      "bbox :->  370\n",
      "bbox :->  109\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  380\n",
      "bbox :->  96\n",
      "bbox :->  419\n",
      "bbox :->  109\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  112\n",
      "bbox :->  147\n",
      "bbox :->  155\n",
      "bbox :->  161\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  165\n",
      "bbox :->  147\n",
      "bbox :->  204\n",
      "bbox :->  163\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  211\n",
      "bbox :->  147\n",
      "bbox :->  221\n",
      "bbox :->  159\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  229\n",
      "bbox :->  147\n",
      "bbox :->  248\n",
      "bbox :->  162\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  260\n",
      "bbox :->  147\n",
      "bbox :->  303\n",
      "bbox :->  160\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  311\n",
      "bbox :->  146\n",
      "bbox :->  353\n",
      "bbox :->  159\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  364\n",
      "bbox :->  146\n",
      "bbox :->  381\n",
      "bbox :->  162\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  196\n",
      "bbox :->  170\n",
      "bbox :->  247\n",
      "bbox :->  184\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  255\n",
      "bbox :->  170\n",
      "bbox :->  295\n",
      "bbox :->  184\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  164\n",
      "bbox :->  195\n",
      "bbox :->  209\n",
      "bbox :->  208\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  215\n",
      "bbox :->  194\n",
      "bbox :->  268\n",
      "bbox :->  207\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  276\n",
      "bbox :->  194\n",
      "bbox :->  329\n",
      "bbox :->  208\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  219\n",
      "bbox :->  217\n",
      "bbox :->  271\n",
      "bbox :->  231\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  165\n",
      "bbox :->  373\n",
      "bbox :->  250\n",
      "bbox :->  389\n",
      "text\n",
      "Unspecified\n",
      "0\n",
      "0\n",
      "\n",
      "      \n",
      "bbox :->  412\n",
      "bbox :->  599\n",
      "bbox :->  443\n",
      "bbox :->  610\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(xml_f)\n",
    "root = tree.getroot()\n",
    "print('\\nAll item data:')\n",
    "for elem in root:\n",
    "    for subelem in elem:\n",
    "        print(subelem.text)\n",
    "        for bbox in subelem:\n",
    "            print('bbox :-> ',bbox.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(img_file[4])\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) # grayscale\n",
    "_,thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY_INV) # threshold\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "dilated = cv2.dilate(thresh,kernel,iterations = 13) # dilate\n",
    "contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE) # get contours\n",
    "\n",
    "# for each contour found, draw a rectangle around it on original image\n",
    "for contour in contours:\n",
    "    # get rectangle bounding contour\n",
    "    [x,y,w,h] = cv2.boundingRect(contour)\n",
    "\n",
    "    # discard areas that are too large\n",
    "    if h>300 and w>300:\n",
    "        continue\n",
    "\n",
    "    # discard areas that are too small\n",
    "    if h<40 or w<40:\n",
    "        continue\n",
    "\n",
    "    # draw rectangle around contour on original image\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "\n",
    "# write original image with added contours to disk  \n",
    "cv2.imshow(\"contoured.jpg\", image)\n",
    "# cv2.imwrite(\"contoured.jpg\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trevaller_policy",
   "language": "python",
   "name": "trevaller_policy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
