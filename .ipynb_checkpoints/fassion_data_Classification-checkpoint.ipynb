{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch utility imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#neural net imports\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0      2       0       0       0       0       0       0       0       0   \n",
      "1      9       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "\n",
      "[2 rows x 785 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv('../input/fashionmnist/fashion-mnist_test.csv')\n",
    "print(train_df.head(2))\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 6]\n",
      "(60000,)\n",
      "[0 1 2]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# labels = data_df['label'].values.tolist()\n",
    "train_labels = train_df['label'].to_numpy()\n",
    "test_labels = test_df['label'].to_numpy()\n",
    "# print(labels)\n",
    "print(train_labels[:3])\n",
    "print(train_labels.shape)\n",
    "print(test_labels[:3])\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# img_data = data_df.iloc[:,1:].values.tolist()\n",
    "train_img_data = train_df.iloc[:,1:].to_numpy()\n",
    "test_img_data = test_df.iloc[:,1:].to_numpy()\n",
    "print(train_img_data.shape)\n",
    "print(test_img_data.shape)\n",
    "\n",
    "train_img_data = train_img_data.reshape(len(train_img_data),28,28)\n",
    "test_img_data = test_img_data.reshape(len(test_img_data),28,28)\n",
    "\n",
    "print(train_img_data.shape)\n",
    "print(test_img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'boot'}\n"
     ]
    }
   ],
   "source": [
    "label =\"\"\"0 T-shirt/top\n",
    "1 Trouser\n",
    "2 Pullover\n",
    "3 Dress\n",
    "4 Coat\n",
    "5 Sandal\n",
    "6 Shirt\n",
    "7 Sneaker\n",
    "8 Bag\n",
    "9 Ankle boot\"\"\".split(\"\\n\")\n",
    "id_2_label ={key:value.split()[-1] for key,value in enumerate(label)} \n",
    "label_2_id ={value.split()[-1]:key  for key,value in enumerate(label)}\n",
    "print(id_2_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img,title='Image'):\n",
    "    \n",
    "    channel = len(img.shape)\n",
    "    \n",
    "    if channel <= 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANGUlEQVR4nO3dbWiV9xnH8d+lNk8+m6ZO50NrJ8XVtVA6Vyx0UIWyibV9IWQPdHuxFmbnilDKyrqig2FeDLbBDCuFvugLO1QYjIIw3DsHa23Vus41BbckNrY+RG00xtjqvRc5bmF4X1eWe2mu474fEEp+3ufc55z8eodc/v+3FUUhAPlMmewTAHBjlBNIinICSVFOICnKCSRFOYGkKCeQFOVMwsy6zWztZJ8H8qCcQFKUMxkz+66Z/cnMfmFm583s72a2uvb142Z2ysy+M+rvrzOzQ2Y2UMu3/sfjPWFmPWbWb2Y/GX2FNrMpZvYjMztWy3eZ2bzP+CWjBOXM6SuSjkhqlbRT0m8lfVnSFyR9W9KvzWxG7e8OSnpC0hxJ6yR938wekyQz+6KkTknfkrRA0mxJnx/1PD+U9Jikr0paKOmcpB0T+cIwdsa/rc3BzLolfU/SIkk/Lopiee3rX9JIUT9XFMXJ2tf6Ja0piuLwDR7nl5KKoii2mNmLklYURfGNWtYi6bykrxdFsc/M/ibpB0VR/LGWL5DUK6m5KIpPJ/YVIzJtsk8AN3Ry1H8PSdL1Yo762gxJMrOvSOqQtFJSg6RGSbtrf2+hpOPXDyqK4lKt2NctlfQ7M7s26mtXJc2X1Pc/eSUYN36srX87Jf1e0uKiKGZL+o0kq2UfauRKLEkys2aN/Kh83XFJXyuKYs6oP01FUVDMBChn/Zsp6WxRFJfNbJWkb47K9khaX/uFUoOkbfp3caWRIv/MzJZKkpm1mdmGz+rE4aOc9W+TpJ+a2QVJL0radT0oiuKvkjZr5BdKH0q6IOmUpOHaX/mVRq66f6gd/2eN/DIKCfALof8jtd/wnpe0vCiKf0z2+cDHlfMmZ2brzazFzKZL+rmkv0jqntyzwlhQzpvfBkknan+WS2ov+HGpLvBjLZAUV04gKfcfIZgZl1VgghVFYTf6OldOICnKCSRFOYGkKCeQFOUEkqKcQFKUE0iKcgJJUU4gKcoJJEU5gaQoJ5AU5QSSopxAUpQTSIpyAklRTiApygkkRTmBpCgnkBTlBJKinEBSae/POW2af2qffpr33q4PPfSQm1+7dq006+rqco9tampy8ytXrrj5okWL3Hzjxo2l2euvv+4eu3//fjfHf4crJ5AU5QSSopxAUpQTSIpyAklRTiApygkk5d4892a9BWB7e7ubb9myxc0XLlzo5t4cU5KWLFlSmj377LPusQcOHHDzdevWuflzzz3n5mfOnCnNLly44B57xx13uHlHR4ebP//8825+s+IWgECdoZxAUpQTSIpyAklRTiApygkkRTmBpOp2znnvvfe6+dtvv12anT171j02Wks6MDDg5kNDQ27umTVrlptv377dzR955BE3j9ZzNjY2lmYtLS3jPlaS5s2b5+a33HJLaXbPPfe4x7777rtunhlzTqDOUE4gKcoJJEU5gaQoJ5AU5QSSopxAUhM65zS74fhGkuQ971gcPXrUzb39XS9evOgeO3XqVDefPn26m3uvW5IuX7487udetmyZm58+fdrNoxntlCnl/7+O9gpuaGhw82ida2tra2kWzX+98x6L6DOr+v0aPDZzTqCeUE4gKcoJJEU5gaQoJ5AU5QSSctdGVf31cpVfP2/dutXN58+f7+a9vb2l2dy5c8dzSv9y7tw5N29ubnZzb6QwPDzsHnvkyBE3j0Yx0bIvb/vLaIR06dIlN585c6abHz9+vDSLtiPt7Ox0802bNrn5RI5KxosrJ5AU5QSSopxAUpQTSIpyAklRTiApygkkVWnJWLRMJ1oi5Onv73fzjz/+2M29eaG3ZEuKZ4XR/Dd6X7xz85a6SfE8rups+urVq6WZt3XlWB47et+998VbTiZJy5cvd/NoyVl0e0PvM63yfS6xZAyoO5QTSIpyAklRTiApygkkRTmBpCgnkJR/r7tAlTnnxo0b3WOjtYHR9pbevDBaMxmtW/RmgVI8z5sxY0Zp9sknn7jHVl13GM1BvRlvtDVmdG7R++qJ3pePPvrIzV999VU3f/zxx9286ixzPLhyAklRTiApygkkRTmBpCgnkBTlBJKinEBSE3oLQE9XV5ebNzY2uvnQ0NC486r77Ub7r0a5NweNZrDRnrhRfuXKFTf31mxGs8Zo/hvt9zttWvnY3cukeA45Z84cN1+9erWb9/T0lGbRuY1hPsx6TqCeUE4gKcoJJEU5gaQoJ5AU5QSSopxAUu6cc8qUKe7AL5oHtrW1lWZvvfWWe+zAwICbR7xZYrQ3bLTHaXd3t5u/+eabbu7NAx988EH32MOHD7t5NOeMZo2Dg4Ol2bJly9xj77zzTjeP7rF5/vz50iyaHUfz4Wjf2zfeeMPNN2zY4OZVMOcE6gzlBJKinEBSlBNIinICSVFOICl3rUvVbRifeuqp0izaojFaZhMt02loaCjNomVT0Zafx44dc/ODBw+6uTeque+++9xjo6Vy77zzjpt74y3JH3dEn0k0/lq8eLGbe98T0WcWnZs3ppGkRx991M29UU50+8Doe70MV04gKcoJJEU5gaQoJ5AU5QSSopxAUpQTSGpCt8bs7e0tzaIlPtHSJm+OKflbJVa9VV20ZOyDDz5wc29md/fdd7vHnjx50s2j99Xb+lKSbr311tIs2n4yWmoXLdvyltJF225GonO/7bbb3HzXrl2l2ebNm8d1TtexZAyoM5QTSIpyAklRTiApygkkRTmBpCgnkFSlOefKlSvdB9+7d29pFs3rWlpa3Dyae3m3EIzWgkZz0Gj7yeh4b9tOL5PiGWx0btEc1JvBRq8rWgc7depUN/ceP1rPGb2uaDvU6PaGK1asKM2i1x1hzgnUGcoJJEU5gaQoJ5AU5QSSopxAUpQTSMof+AW2bNni5t7cKpqZRXOraFbp7e8arQW9dOmSm0cz2mjW6O1jGr3uixcvunm0f2v02r2ZXbQWNJo9R8893v1dpfj7IZpjRvmZM2dKs6effto9dseOHW5ehisnkBTlBJKinEBSlBNIinICSVFOICnKCSRVaT3n6dOn3Qc/depUaRbdZ9JbjynFc1Ivj2Zig4ODbh7NxKJz99ZkRmsDozlmtD9r9L55jx/NOaO1qNGaSu99i2ao0euK1oNGM1bv/pzR6/LueSqxnhOoO5QTSIpyAklRTiApygkkRTmBpNyZwv333+8e7N0uTvJvhReNBKJxR5XlS1WXNkXPHY1aBgYGSrMq4wYp3n4y4r32aEwTnXs0zvA+c+89k+JxRX9/v5tHn6k3Xou+lxcsWODmZbhyAklRTiApygkkRTmBpCgnkBTlBJKinEBS7jDx4Ycfdg9+//333dyba0WzxKq8mVw054yWD0Uz2Crbdkbbckazxujcq+TR+xbNWKNZ4pIlS0qzzs5O91hv60pJ6ujocPMDBw64ufe+RHPM9vZ2Ny/DlRNIinICSVFOICnKCSRFOYGkKCeQFOUEknK3xtyzZ4+73+CaNWvcB+/r6yvNom0U586d6+bRGjpvLhU9dzRLjPJonuedW7QWNHruaGvNaBbpHV/1NnvRZzZ79uzSrK2tzT121qxZbt7d3e3mLS0tbu6d+6FDh9xjn3zySTfv6+tja0ygnlBOICnKCSRFOYGkKCeQFOUEkqKcQFLu4OqFF15wDz5x4oSbP/DAA6XZqlWr3GNfeeUVNz969Kibb9++vTQ7ePCge2y0N2y0JrLKvrjRvC1a7xndCi86N2+OGs0xm5ubKz23J5qRRm6//XY337dvn5u/9NJLpdnu3bvHc0ohrpxAUpQTSIpyAklRTiApygkkRTmBpNxRSldXl3vwM888M+4nXrp0qZv39PS4+bZt29zcWxoVjSOiUUq0LCvijSSikUG0HC0SLTmrIjr36BaA3mvbu3fvuM5prNauXTuhjz8eXDmBpCgnkBTlBJKinEBSlBNIinICSVFOICl3zhnN86rMzKI5ZuS9995zc29ZV7S0Kdo6c3h42M2j7Se9PFqOFn0mE3kLwGg5WiQ63puTRrPpSPSZVBG9rvH2hCsnkBTlBJKinEBSlBNIinICSVFOICnKCSTlzjmrrv3zZmZVbyf32muvufnOnTtLs9bWVvfYpqYmN/e2tpTic/e2iKx6+8Gqs0jv8aPPLHruoaEhN/du47d//3732MhEzSInEldOICnKCSRFOYGkKCeQFOUEkqKcQFKUE0jKvPmPmVUbmk2il19+uTS766673GOjWxtWXVNZZd/baMZadU7qzWCrrMeU4n1r582bV5qtX7/ePTYSfSbRa5vgda43fHCunEBSlBNIinICSVFOICnKCSRFOYGkKCeQ1E075wTqBXNOoM5QTiApygkkRTmBpCgnkBTlBJKinEBSlBNIinICSVFOICnKCSRFOYGkKCeQFOUEkqKcQFKUE0iKcgJJUU4gKcoJJEU5gaQoJ5AU5QSScrfGBDB5uHICSVFOICnKCSRFOYGkKCeQFOUEkvonV5EVQADYO2cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(train_img_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CreateModel,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16,out_channels=64,kernel_size=3)\n",
    "        \n",
    "        # third hidden layer (Fully connected layer)\n",
    "        self.fc1 = nn.Linear(in_features=64*(4 * 4),out_features=120)\n",
    "        # fourth hidden layer (Fully connected layer)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        #output layer\n",
    "        self.out= nn.Linear(in_features=84,out_features=10)\n",
    "    \n",
    "   \n",
    "    def forward(self, t): #flow of the data/tensor\n",
    "#         input layer\n",
    "#         print('input : ',t.size())\n",
    "        t=t.float()\n",
    "#         hidden layer 1\n",
    "        t=self.conv1(t)\n",
    "#         print('conv1 : ',t.size())\n",
    "        t=F.relu(t)   #   convolution operation\n",
    "        t=F.max_pool2d(t,kernel_size =2, stride=2)\n",
    "#         print('max_poll1 : ',t.size())\n",
    "#         hidden layer 2\n",
    "        t=self.conv2(t)\n",
    "#         print('conv2 : ',t.size())\n",
    "        t=F.relu(t)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=1)\n",
    "#         print('max_poll2 : ',t.size())\n",
    "#         hidden layer 3\n",
    "        t=self.conv3(t)\n",
    "#         print('conv3 : ',t.size())\n",
    "        t=F.relu(t)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "#         print('max_poll2 : ',t.size())\n",
    "#         flatten\n",
    "#         t=t.reshape(-1, 64*(4*4))\n",
    "        t = t.view(-1, self.num_flat_features(t))\n",
    "#         print('before fc : ',t.size())\n",
    "#         t=t.view(-1, (64*4*4))\n",
    "#         hidden layer 4 (fully connected)\n",
    "        t=self.fc1(t)\n",
    "#         print('fc1 : ',t.size())\n",
    "        t=F.relu(t)\n",
    "#         hidden layer 5 (fully connected)\n",
    "        t = self.fc2(t)\n",
    "#         print('fc2 : ',t.size())\n",
    "        t = F.relu(t)\n",
    "#         output layer\n",
    "        t=self.out(t)\n",
    "#         print(t)\n",
    "        t=F.log_softmax(t,1)\n",
    "        return t\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "#         print('num_flat : ', x.size())\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "#         print('num_features in : ',num_features)\n",
    "        return num_features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28)   (5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(test_img_data, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "print(x_val.shape,' ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(train_img_data)\n",
    "y_train =torch.from_numpy(train_labels)\n",
    "\n",
    "\n",
    "# x_test_data = torch.from_numpy(x_test)\n",
    "# y_test_data= torch.from_numpy(y_test)\n",
    "\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val= torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        data, target = data, target\n",
    "        data = data.reshape(batch_size,-1,28,28)\n",
    "#         print('data.size :',data.size())\n",
    "#         data = data.unsqueeze(1)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = compute_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 60 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                num_epoch, (batch_idx + 1) * len(data), len(train_dataloader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_dataloader), loss.item()))\n",
    "#         break\n",
    "            \n",
    "def evaluate(val_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_dataloader:\n",
    "#         data = data.unsqueeze(1)\n",
    "        data, target = data, target\n",
    "        data=data.reshape(batch_size,-1,28,28)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss +=compute_loss(output, target).item()\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(test_dataloader.dataset)\n",
    "        \n",
    "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(val_dataloader.dataset),\n",
    "        100. * correct / len(val_dataloader.dataset)))\n",
    "\n",
    "def predict(model,img=[],desc=False,topk=5,class_name_dict=None):\n",
    "    correct=0\n",
    "    size = len(img)\n",
    "#     print('betch size :',size)\n",
    "    w,h=img[0].shape\n",
    "    if size == 1:\n",
    "        img=torch.from_numpy(img[0])\n",
    "    else:\n",
    "        img=torch.from_numpy(img)\n",
    "    img= img.reshape(size,-1,w,h)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        img= img.cuda()\n",
    "    output = model(img)\n",
    "    if desc:\n",
    "        infer_pred(class_name_dict,output,betch=size)\n",
    "    pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "    pred = pred.numpy()\n",
    "    if size==1:\n",
    "        print('Predicted id : ', pred[0])\n",
    "    return pred\n",
    "\n",
    "        \n",
    "def infer_pred(id_2_label,output,topk=5, betch=1):\n",
    "    pred_prob= nn.functional.softmax(output)\n",
    "    _,top_K_prob=pred_prob.topk(topk)\n",
    "    top_K_prob =top_K_prob.cpu().numpy()\n",
    "    pred_prob=pred_prob.cpu().detach().numpy()\n",
    "    c=0\n",
    "    for j in range(betch):\n",
    "        print('\\ntop {} are confidance scores are for Betch ({})  : '.format(topk, j))\n",
    "        print('No   Pred_id   label      confidance')\n",
    "        for i in range(topk):\n",
    "            c=c+1\n",
    "            print(\"{},    {},       {},     {} %\\\n",
    "            \".format(c,top_K_prob[j][i],id_2_label[top_K_prob[j][i]],pred_prob[j][i]*100))\n",
    "#         print(top_K_prob[j])\n",
    "#         max_id=np.where(top_K_prob[j] == np.amax(top_K_prob[j]))[0][0]\n",
    "        print('\\nPredicted Class: **{}**'.format(id_2_label[np.amax(top_K_prob[j])]))\n",
    "    \n",
    "def get_correct_prediction(id_2_label,pred, labels):\n",
    "    infer_list=[]\n",
    "    match_list=[]\n",
    "    incorrect_list=[]\n",
    "    correct =0\n",
    "    infer_list.append(['index' ,'Classs Name','Predicted', 'True value', 'Mismatch'])\n",
    "    for idx,y in enumerate(pred):\n",
    "        if y==labels[idx]:\n",
    "            match_list.append(idx)\n",
    "            correct +=1\n",
    "            infer_list.append([idx,id_2_label[y[0]],y[0],labels[idx],True])\n",
    "        else:\n",
    "            incorrect_list.append((idx, y[0],labels[idx]))\n",
    "            infer_list.append([idx,id_2_label[y[0]],y[0],labels[idx],False])\n",
    "    print('Totla : {} , correct prediciton : {} , incorrect : {} \\n'.format(len(labels),correct,len(labels)- correct))\n",
    "    print('Accuracy : {}%'.format(100. * correct / len(labels)))\n",
    "    return tuple(infer_list), tuple(match_list), tuple(incorrect_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CreateModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "batch_size=1000\n",
    "# batch_size=1\n",
    "epochs = 200\n",
    "compute_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(params=conv_model.parameters(), lr=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.TensorDataset'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset=TensorDataset(x_train,y_train) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size) # create your dataloader\n",
    "\n",
    "# test_dataset=TensorDataset(x_test,y_test) # create your datset\n",
    "# test_dataloader =DataLoader(train_dataset,batch_size=batch_size) # create your dataloader\n",
    "\n",
    "val_dataset=TensorDataset(x_val,y_val) # create your datset\n",
    "val_dataloader =DataLoader(val_dataset,batch_size=batch_size) # create your dataloader\n",
    "\n",
    "print(type(train_dataset))\n",
    "print(type(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training..\n",
      "\n",
      "Train Epoch: 0 [60000/60000 (100%)]\tLoss: 0.679518\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0001, Val Accuracy: 3755/5000 (75.100%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 1 [60000/60000 (100%)]\tLoss: 0.581099\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 3977/5000 (79.540%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 2 [60000/60000 (100%)]\tLoss: 0.507257\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4060/5000 (81.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 3 [60000/60000 (100%)]\tLoss: 0.471796\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4126/5000 (82.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 4 [60000/60000 (100%)]\tLoss: 0.443883\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4209/5000 (84.180%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 5 [60000/60000 (100%)]\tLoss: 0.403345\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4210/5000 (84.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 6 [60000/60000 (100%)]\tLoss: 0.411444\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4263/5000 (85.260%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 7 [60000/60000 (100%)]\tLoss: 0.379773\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4282/5000 (85.640%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 8 [60000/60000 (100%)]\tLoss: 0.365237\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4298/5000 (85.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 9 [60000/60000 (100%)]\tLoss: 0.357897\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4330/5000 (86.600%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 10 [60000/60000 (100%)]\tLoss: 0.348808\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4343/5000 (86.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 11 [60000/60000 (100%)]\tLoss: 0.341010\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4349/5000 (86.980%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 12 [60000/60000 (100%)]\tLoss: 0.332559\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4365/5000 (87.300%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 13 [60000/60000 (100%)]\tLoss: 0.325652\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4384/5000 (87.680%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 14 [60000/60000 (100%)]\tLoss: 0.319265\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4394/5000 (87.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 15 [60000/60000 (100%)]\tLoss: 0.313630\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4399/5000 (87.980%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 16 [60000/60000 (100%)]\tLoss: 0.307882\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4403/5000 (88.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 17 [60000/60000 (100%)]\tLoss: 0.302623\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4419/5000 (88.380%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 18 [60000/60000 (100%)]\tLoss: 0.298351\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4424/5000 (88.480%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 19 [60000/60000 (100%)]\tLoss: 0.295951\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4433/5000 (88.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 20 [60000/60000 (100%)]\tLoss: 0.293595\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4440/5000 (88.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 21 [60000/60000 (100%)]\tLoss: 0.291533\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4436/5000 (88.720%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 22 [60000/60000 (100%)]\tLoss: 0.289441\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4416/5000 (88.320%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 23 [60000/60000 (100%)]\tLoss: 0.282014\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4405/5000 (88.100%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 24 [60000/60000 (100%)]\tLoss: 0.279089\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4418/5000 (88.360%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 25 [60000/60000 (100%)]\tLoss: 0.275239\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4426/5000 (88.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 26 [60000/60000 (100%)]\tLoss: 0.270518\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4426/5000 (88.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 27 [60000/60000 (100%)]\tLoss: 0.266364\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4433/5000 (88.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 28 [60000/60000 (100%)]\tLoss: 0.263003\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4430/5000 (88.600%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 29 [60000/60000 (100%)]\tLoss: 0.259961\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4435/5000 (88.700%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 30 [60000/60000 (100%)]\tLoss: 0.255929\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4436/5000 (88.720%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 31 [60000/60000 (100%)]\tLoss: 0.253162\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4432/5000 (88.640%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 32 [60000/60000 (100%)]\tLoss: 0.250453\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4441/5000 (88.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 33 [60000/60000 (100%)]\tLoss: 0.247425\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 34 [60000/60000 (100%)]\tLoss: 0.244519\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4443/5000 (88.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 35 [60000/60000 (100%)]\tLoss: 0.242757\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4441/5000 (88.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 36 [60000/60000 (100%)]\tLoss: 0.239669\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 37 [60000/60000 (100%)]\tLoss: 0.236251\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4453/5000 (89.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 38 [60000/60000 (100%)]\tLoss: 0.233305\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4454/5000 (89.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 39 [60000/60000 (100%)]\tLoss: 0.230256\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4458/5000 (89.160%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 40 [60000/60000 (100%)]\tLoss: 0.227972\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4458/5000 (89.160%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 41 [60000/60000 (100%)]\tLoss: 0.225146\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4462/5000 (89.240%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 42 [60000/60000 (100%)]\tLoss: 0.222089\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4457/5000 (89.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 43 [60000/60000 (100%)]\tLoss: 0.220696\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4464/5000 (89.280%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 44 [60000/60000 (100%)]\tLoss: 0.218285\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4469/5000 (89.380%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 45 [60000/60000 (100%)]\tLoss: 0.215309\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4473/5000 (89.460%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 46 [60000/60000 (100%)]\tLoss: 0.213989\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4476/5000 (89.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 47 [60000/60000 (100%)]\tLoss: 0.212114\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4482/5000 (89.640%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 48 [60000/60000 (100%)]\tLoss: 0.210069\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4483/5000 (89.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 49 [60000/60000 (100%)]\tLoss: 0.207906\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4491/5000 (89.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 50 [60000/60000 (100%)]\tLoss: 0.204839\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4490/5000 (89.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 51 [60000/60000 (100%)]\tLoss: 0.203167\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4491/5000 (89.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 52 [60000/60000 (100%)]\tLoss: 0.200858\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4493/5000 (89.860%)\n",
      "\n",
      "starting training..\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 53 [60000/60000 (100%)]\tLoss: 0.198881\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4490/5000 (89.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 54 [60000/60000 (100%)]\tLoss: 0.196511\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4500/5000 (90.000%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 55 [60000/60000 (100%)]\tLoss: 0.195282\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4498/5000 (89.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 56 [60000/60000 (100%)]\tLoss: 0.193462\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4501/5000 (90.020%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 57 [60000/60000 (100%)]\tLoss: 0.191458\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4504/5000 (90.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 58 [60000/60000 (100%)]\tLoss: 0.189096\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4505/5000 (90.100%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 59 [60000/60000 (100%)]\tLoss: 0.186935\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4502/5000 (90.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 60 [60000/60000 (100%)]\tLoss: 0.185851\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4511/5000 (90.220%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 61 [60000/60000 (100%)]\tLoss: 0.185454\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4513/5000 (90.260%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 62 [60000/60000 (100%)]\tLoss: 0.185160\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4510/5000 (90.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 63 [60000/60000 (100%)]\tLoss: 0.184765\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4503/5000 (90.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 64 [60000/60000 (100%)]\tLoss: 0.183938\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4503/5000 (90.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 65 [60000/60000 (100%)]\tLoss: 0.183314\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4499/5000 (89.980%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 66 [60000/60000 (100%)]\tLoss: 0.182231\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4498/5000 (89.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 67 [60000/60000 (100%)]\tLoss: 0.180664\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4497/5000 (89.940%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 68 [60000/60000 (100%)]\tLoss: 0.179734\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4496/5000 (89.920%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 69 [60000/60000 (100%)]\tLoss: 0.179206\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4509/5000 (90.180%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 70 [60000/60000 (100%)]\tLoss: 0.176291\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4504/5000 (90.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 71 [60000/60000 (100%)]\tLoss: 0.175358\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4498/5000 (89.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 72 [60000/60000 (100%)]\tLoss: 0.173346\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4491/5000 (89.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 73 [60000/60000 (100%)]\tLoss: 0.171941\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4495/5000 (89.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 74 [60000/60000 (100%)]\tLoss: 0.170918\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4493/5000 (89.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 75 [60000/60000 (100%)]\tLoss: 0.169605\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4494/5000 (89.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 76 [60000/60000 (100%)]\tLoss: 0.165566\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4493/5000 (89.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 77 [60000/60000 (100%)]\tLoss: 0.162674\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4497/5000 (89.940%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 78 [60000/60000 (100%)]\tLoss: 0.160341\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4498/5000 (89.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 79 [60000/60000 (100%)]\tLoss: 0.157427\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4502/5000 (90.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 80 [60000/60000 (100%)]\tLoss: 0.155891\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4494/5000 (89.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 81 [60000/60000 (100%)]\tLoss: 0.154232\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4487/5000 (89.740%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 82 [60000/60000 (100%)]\tLoss: 0.152770\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4481/5000 (89.620%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 83 [60000/60000 (100%)]\tLoss: 0.155959\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4476/5000 (89.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 84 [60000/60000 (100%)]\tLoss: 0.169523\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4458/5000 (89.160%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 85 [60000/60000 (100%)]\tLoss: 0.182268\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4440/5000 (88.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 86 [60000/60000 (100%)]\tLoss: 0.161970\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4434/5000 (88.680%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 87 [60000/60000 (100%)]\tLoss: 0.152050\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4462/5000 (89.240%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 88 [60000/60000 (100%)]\tLoss: 0.141994\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4484/5000 (89.680%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 89 [60000/60000 (100%)]\tLoss: 0.140627\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4492/5000 (89.840%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 90 [60000/60000 (100%)]\tLoss: 0.144262\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4479/5000 (89.580%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 91 [60000/60000 (100%)]\tLoss: 0.155561\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4441/5000 (88.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 92 [60000/60000 (100%)]\tLoss: 0.167990\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4401/5000 (88.020%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 93 [60000/60000 (100%)]\tLoss: 0.157265\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4435/5000 (88.700%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 94 [60000/60000 (100%)]\tLoss: 0.149790\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4450/5000 (89.000%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 95 [60000/60000 (100%)]\tLoss: 0.163762\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4465/5000 (89.300%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 96 [60000/60000 (100%)]\tLoss: 0.159074\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4462/5000 (89.240%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 97 [60000/60000 (100%)]\tLoss: 0.159187\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4457/5000 (89.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 98 [60000/60000 (100%)]\tLoss: 0.152299\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4444/5000 (88.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 99 [60000/60000 (100%)]\tLoss: 0.147096\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4436/5000 (88.720%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 100 [60000/60000 (100%)]\tLoss: 0.146518\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4428/5000 (88.560%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 101 [60000/60000 (100%)]\tLoss: 0.144824\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4432/5000 (88.640%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 102 [60000/60000 (100%)]\tLoss: 0.144179\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4439/5000 (88.780%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 103 [60000/60000 (100%)]\tLoss: 0.141520\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4429/5000 (88.580%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 104 [60000/60000 (100%)]\tLoss: 0.135549\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4421/5000 (88.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 105 [60000/60000 (100%)]\tLoss: 0.128792\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4434/5000 (88.680%)\n",
      "\n",
      "starting training..\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 106 [60000/60000 (100%)]\tLoss: 0.123893\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4437/5000 (88.740%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 107 [60000/60000 (100%)]\tLoss: 0.120531\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4428/5000 (88.560%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 108 [60000/60000 (100%)]\tLoss: 0.117450\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4444/5000 (88.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 109 [60000/60000 (100%)]\tLoss: 0.115723\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4449/5000 (88.980%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 110 [60000/60000 (100%)]\tLoss: 0.115074\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4434/5000 (88.680%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 111 [60000/60000 (100%)]\tLoss: 0.112581\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4439/5000 (88.780%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 112 [60000/60000 (100%)]\tLoss: 0.110398\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4443/5000 (88.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 113 [60000/60000 (100%)]\tLoss: 0.107774\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4437/5000 (88.740%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 114 [60000/60000 (100%)]\tLoss: 0.108366\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4444/5000 (88.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 115 [60000/60000 (100%)]\tLoss: 0.108174\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 116 [60000/60000 (100%)]\tLoss: 0.106155\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4447/5000 (88.940%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 117 [60000/60000 (100%)]\tLoss: 0.103632\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4440/5000 (88.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 118 [60000/60000 (100%)]\tLoss: 0.105670\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4435/5000 (88.700%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 119 [60000/60000 (100%)]\tLoss: 0.108377\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4436/5000 (88.720%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 120 [60000/60000 (100%)]\tLoss: 0.109074\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4407/5000 (88.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 121 [60000/60000 (100%)]\tLoss: 0.105952\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4394/5000 (87.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 122 [60000/60000 (100%)]\tLoss: 0.099041\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4402/5000 (88.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 123 [60000/60000 (100%)]\tLoss: 0.099070\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4394/5000 (87.880%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 124 [60000/60000 (100%)]\tLoss: 0.105706\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4417/5000 (88.340%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 125 [60000/60000 (100%)]\tLoss: 0.117346\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4468/5000 (89.360%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 126 [60000/60000 (100%)]\tLoss: 0.109449\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4475/5000 (89.500%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 127 [60000/60000 (100%)]\tLoss: 0.103453\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4473/5000 (89.460%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 128 [60000/60000 (100%)]\tLoss: 0.109217\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4451/5000 (89.020%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 129 [60000/60000 (100%)]\tLoss: 0.101502\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 130 [60000/60000 (100%)]\tLoss: 0.101381\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4459/5000 (89.180%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 131 [60000/60000 (100%)]\tLoss: 0.121980\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4467/5000 (89.340%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 132 [60000/60000 (100%)]\tLoss: 0.144899\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4446/5000 (88.920%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 133 [60000/60000 (100%)]\tLoss: 0.133061\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4471/5000 (89.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 134 [60000/60000 (100%)]\tLoss: 0.159273\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4469/5000 (89.380%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 135 [60000/60000 (100%)]\tLoss: 0.134023\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4468/5000 (89.360%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 136 [60000/60000 (100%)]\tLoss: 0.133616\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4453/5000 (89.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 137 [60000/60000 (100%)]\tLoss: 0.129818\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4457/5000 (89.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 138 [60000/60000 (100%)]\tLoss: 0.119080\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4462/5000 (89.240%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 139 [60000/60000 (100%)]\tLoss: 0.114027\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4458/5000 (89.160%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 140 [60000/60000 (100%)]\tLoss: 0.113883\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4460/5000 (89.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 141 [60000/60000 (100%)]\tLoss: 0.107620\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4460/5000 (89.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 142 [60000/60000 (100%)]\tLoss: 0.111448\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4440/5000 (88.800%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 143 [60000/60000 (100%)]\tLoss: 0.109932\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4426/5000 (88.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 144 [60000/60000 (100%)]\tLoss: 0.103314\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4447/5000 (88.940%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 145 [60000/60000 (100%)]\tLoss: 0.095894\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4465/5000 (89.300%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 146 [60000/60000 (100%)]\tLoss: 0.094222\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4485/5000 (89.700%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 147 [60000/60000 (100%)]\tLoss: 0.099032\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4493/5000 (89.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 148 [60000/60000 (100%)]\tLoss: 0.099844\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4493/5000 (89.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 149 [60000/60000 (100%)]\tLoss: 0.100843\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4473/5000 (89.460%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 150 [60000/60000 (100%)]\tLoss: 0.100328\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4471/5000 (89.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 151 [60000/60000 (100%)]\tLoss: 0.106741\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4457/5000 (89.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 152 [60000/60000 (100%)]\tLoss: 0.107519\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4454/5000 (89.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 153 [60000/60000 (100%)]\tLoss: 0.111882\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4460/5000 (89.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 154 [60000/60000 (100%)]\tLoss: 0.100176\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4468/5000 (89.360%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 155 [60000/60000 (100%)]\tLoss: 0.094301\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4452/5000 (89.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 156 [60000/60000 (100%)]\tLoss: 0.094732\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4451/5000 (89.020%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 157 [60000/60000 (100%)]\tLoss: 0.095260\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4442/5000 (88.840%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 158 [60000/60000 (100%)]\tLoss: 0.097733\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4446/5000 (88.920%)\n",
      "\n",
      "starting training..\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 159 [60000/60000 (100%)]\tLoss: 0.102947\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4454/5000 (89.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 160 [60000/60000 (100%)]\tLoss: 0.097104\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4443/5000 (88.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 161 [60000/60000 (100%)]\tLoss: 0.085672\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4439/5000 (88.780%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 162 [60000/60000 (100%)]\tLoss: 0.091310\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4433/5000 (88.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 163 [60000/60000 (100%)]\tLoss: 0.092928\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 164 [60000/60000 (100%)]\tLoss: 0.091451\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4433/5000 (88.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 165 [60000/60000 (100%)]\tLoss: 0.086313\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4431/5000 (88.620%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 166 [60000/60000 (100%)]\tLoss: 0.080865\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4421/5000 (88.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 167 [60000/60000 (100%)]\tLoss: 0.076610\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4425/5000 (88.500%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 168 [60000/60000 (100%)]\tLoss: 0.074976\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4422/5000 (88.440%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 169 [60000/60000 (100%)]\tLoss: 0.073013\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4441/5000 (88.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 170 [60000/60000 (100%)]\tLoss: 0.072219\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4457/5000 (89.140%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 171 [60000/60000 (100%)]\tLoss: 0.068546\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4474/5000 (89.480%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 172 [60000/60000 (100%)]\tLoss: 0.074800\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4477/5000 (89.540%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 173 [60000/60000 (100%)]\tLoss: 0.077223\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4475/5000 (89.500%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 174 [60000/60000 (100%)]\tLoss: 0.084061\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4464/5000 (89.280%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 175 [60000/60000 (100%)]\tLoss: 0.083329\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4450/5000 (89.000%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 176 [60000/60000 (100%)]\tLoss: 0.086444\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4433/5000 (88.660%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 177 [60000/60000 (100%)]\tLoss: 0.117499\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4461/5000 (89.220%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 178 [60000/60000 (100%)]\tLoss: 0.136160\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4453/5000 (89.060%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 179 [60000/60000 (100%)]\tLoss: 0.107087\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4448/5000 (88.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 180 [60000/60000 (100%)]\tLoss: 0.113055\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4423/5000 (88.460%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 181 [60000/60000 (100%)]\tLoss: 0.091824\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4452/5000 (89.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 182 [60000/60000 (100%)]\tLoss: 0.088467\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4449/5000 (88.980%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 183 [60000/60000 (100%)]\tLoss: 0.092103\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4446/5000 (88.920%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 184 [60000/60000 (100%)]\tLoss: 0.075785\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4456/5000 (89.120%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 185 [60000/60000 (100%)]\tLoss: 0.074562\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4441/5000 (88.820%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 186 [60000/60000 (100%)]\tLoss: 0.124804\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4423/5000 (88.460%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 187 [60000/60000 (100%)]\tLoss: 0.110145\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4410/5000 (88.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 188 [60000/60000 (100%)]\tLoss: 0.100863\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4404/5000 (88.080%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 189 [60000/60000 (100%)]\tLoss: 0.084882\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4410/5000 (88.200%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 190 [60000/60000 (100%)]\tLoss: 0.084911\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4411/5000 (88.220%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 191 [60000/60000 (100%)]\tLoss: 0.094335\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4421/5000 (88.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 192 [60000/60000 (100%)]\tLoss: 0.107836\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4426/5000 (88.520%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 193 [60000/60000 (100%)]\tLoss: 0.102060\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4421/5000 (88.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 194 [60000/60000 (100%)]\tLoss: 0.092282\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4443/5000 (88.860%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 195 [60000/60000 (100%)]\tLoss: 0.079511\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4445/5000 (88.900%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 196 [60000/60000 (100%)]\tLoss: 0.067809\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4448/5000 (88.960%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 197 [60000/60000 (100%)]\tLoss: 0.061848\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4452/5000 (89.040%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 198 [60000/60000 (100%)]\tLoss: 0.052951\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4471/5000 (89.420%)\n",
      "\n",
      "starting training..\n",
      "\n",
      "Train Epoch: 199 [60000/60000 (100%)]\tLoss: 0.048208\n",
      "starting evalation \n",
      "\n",
      "\n",
      "Average Val Loss: 0.0000, Val Accuracy: 4475/5000 (89.500%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(epochs):\n",
    "    print('starting training..\\n')\n",
    "    train_model(i)\n",
    "    print('starting evalation \\n')\n",
    "    evaluate(val_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totla : 5000 , correct prediciton : 4510 , incorrect : 490 \n",
      "\n",
      "Accuracy : 90.2%\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "# pred =predict(model, x_test,desc=True, topk=5,class_name_dict=id_2_label)\n",
    "pred =predict(model, x_test)\n",
    "# pred =predict(model, [x_test[0]],desc=True, topk=5,class_name_dict=id_2_label)\n",
    "# pred =predict(model, [x_test[0]])\n",
    "# display_image(test_img_data[idx])\n",
    "# print(test_labels[idx],id_2_label[test_labels[idx]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totla : 5000 , correct prediciton : 4510 , incorrect : 490 \n",
      "\n",
      "Accuracy : 90.2%\n"
     ]
    }
   ],
   "source": [
    "details, match, mismatch= get_correct_prediction(id_2_label,pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_img_size(img, Filter=[None],Stride=[None],Polling=[None]):\n",
    "    if len(img.shape) > 2:\n",
    "        w,h,_= img.shape\n",
    "    else:\n",
    "        w,h =img.shape\n",
    "        \n",
    "    print('W = {}, H = {}'.format(w,h))\n",
    "        \n",
    "    for i in range(len(Filter)):\n",
    "        f = Filter[i]\n",
    "        p= Polling[i] if Polling[i] else 0\n",
    "        s = Stride[i] if Stride[i] else 1\n",
    "        \n",
    "        w = ((w - f + 2 * p)/s) +1\n",
    "        h = ((h - f + 2 * p)/s ) +1\n",
    "        print('layer : ',i+1)\n",
    "        print('new W = {}, new H = {}'.format(w,h))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_out_img_size(train_img_data[0],Filter=[3,2,3,2,3,2],Stride=[0,2,0,0,0,2],Polling=[0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
